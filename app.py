# -*- coding: utf-8 -*-
"""
M√≥dulo Principal da Aplica√ß√£o Flask para Classifica√ß√£o de E-mails.

Esta aplica√ß√£o web permite que o usu√°rio insira o conte√∫do de um e-mail 
ou carregue um arquivo (.txt ou .pdf) para classifica√ß√£o. 
O processo de classifica√ß√£o pode ser executado em tr√™s modos:
1. 'local': Usando um modelo de Machine Learning treinado previamente (e-mail_classifier.joblib).
2. 'openai': Usando a API GPT (necessita de chave).
3. 'gemini': Usando a API Gemini (necessita de chave).

O resultado inclui o r√≥tulo da classifica√ß√£o ('Produtivo' ou 'Improdutivo'),
o n√≠vel de confian√ßa e uma sugest√£o de resposta autom√°tica.

üîß Melhorias adicionadas (do c√≥digo do GPT):
- Heur√≠sticas extras (acad√™micas, anexos, comunica√ß√£o formal).
- Ajuste do threshold (>=0.6 Produtivo, 0.5‚Äì0.6 zona incerta).
- Respostas contextuais aprimoradas no template_reply.

‚úÖ Melhorias de UX (Experi√™ncia do Usu√°rio) implementadas:
- Bug 1: A sele√ß√£o do modelo de IA agora persiste entre as an√°lises.
- Bug 2: O envio de um arquivo agora tem prioridade sobre o texto digitado na caixa.
- Bug 3: A l√≥gica de backend agora suporta o preview do arquivo no frontend.
- Feature: O campo de API Key √© escondido se a chave j√° existir no ambiente do servidor.
"""

# --- Importa√ß√µes de Bibliotecas Essenciais ---
import os           # Para interagir com o sistema operacional (ex: vari√°veis de ambiente, caminhos de arquivo)
import io           # Para trabalhar com streams de I/O em mem√≥ria (necess√°rio para ler arquivos enviados)
import re           # Para express√µes regulares (usado na detec√ß√£o de n√∫meros de pedido/nota)
import json         # Para manipula√ß√£o de dados JSON (usado para comunicar com as APIs de IA)
import traceback    # Para imprimir o stack trace de erros (√∫til para debug)
from flask import Flask, request, render_template # Framework web principal e suas fun√ß√µes

# Biblioteca para carregar o modelo de machine learning local (serializa√ß√£o/desserializa√ß√£o)
import joblib 
# Para ler arquivos PDF e extrair seu texto
import PyPDF2

# --- Importa√ß√µes Opcionais para as APIs de IA ---
# As importa√ß√µes s√£o envolvidas em try/except para que a aplica√ß√£o funcione
# mesmo que as bibliotecas de IA n√£o estejam instaladas (o modo 'local' ainda ser√° funcional).
try:
    import openai
except ImportError:
    openai = None # Se falhar, a vari√°vel √© setada para None, desabilitando o modo 'openai'.

try:
    # ### CORRE√á√ÉO DE ERRO DE DIGITA√á√ÉO ###
    # Corrigido de 'google.generai' para 'google.generativeai'
    import google.generativeai as genai
except ImportError:
    genai = None # Se falhar, a vari√°vel √© setada para None, desabilitando o modo 'gemini'.

# --- Configura√ß√£o Inicial do Flask e do Modelo Local ---
# Inicializa a aplica√ß√£o Flask.
app = Flask(__name__)

# Define o caminho para o arquivo do modelo de ML local.
MODEL_PATH = "models/email_classifier.joblib"
# Vari√°vel para armazenar o modelo carregado.
model = None

# Bloco de inicializa√ß√£o: tenta carregar o modelo de ML na mem√≥ria quando a aplica√ß√£o inicia.
# Isso evita a necessidade de recarregar o modelo a cada requisi√ß√£o, melhorando a performance.
print("--- INICIALIZANDO APLICA√á√ÉO ---")
# Verifica se o arquivo do modelo existe no caminho especificado.
if os.path.exists(MODEL_PATH):
    try:
        # Carrega o modelo de ML usando joblib.
        model = joblib.load(MODEL_PATH)
        print(f"‚úÖ Modelo local carregado com sucesso de '{MODEL_PATH}'")
    except Exception as e:
        # Se ocorrer um erro durante o carregamento (ex: arquivo corrompido),
        # o erro √© logado e a vari√°vel 'model' permanece como None.
        print(f"‚ùå Erro ao carregar o modelo local: {e}")
        model = None
else:
    # Aviso caso o modelo n√£o seja encontrado no deploy. Isso pode acontecer se
    # o script de treinamento n√£o foi executado com sucesso durante o build.
    print(f"‚ö†Ô∏è  Aviso: Modelo local n√£o foi encontrado em '{MODEL_PATH}'. O modo 'local' n√£o funcionar√°.")
print("--- APLICA√á√ÉO PRONTA ---")


# --- Fun√ß√µes Auxiliares de Processamento e Heur√≠stica ---

def extract_text_from_pdf(file_stream):
    """
    Extrai o texto contido em um objeto de arquivo PDF (stream de bytes).

    Args:
        file_stream (io.BytesIO): Stream de bytes do arquivo PDF, vindo do request do Flask.

    Returns:
        str: Todo o texto extra√≠do do PDF, concatenado, ou uma string vazia em caso de erro.
    """
    try:
        # Cria um objeto leitor de PDF a partir do stream de bytes em mem√≥ria.
        reader = PyPDF2.PdfReader(file_stream)
        # Usa uma list comprehension para iterar sobre todas as p√°ginas,
        # extrair o texto de cada uma e juntar tudo em uma √∫nica string com quebras de linha.
        text_pages = [page.extract_text() for page in reader.pages if page.extract_text()]
        return "\n".join(text_pages)
    except Exception as e:
        # Loga o erro de extra√ß√£o no console do servidor para debug.
        print(f"Erro ao extrair texto do PDF: {e}")
        return ""
    
def detect_order_info(text):
    """
    Detecta n√∫meros de pedido, nota fiscal ou identificadores longos no texto usando express√µes regulares.
    
    A presen√ßa de tais n√∫meros √© uma forte heur√≠stica para um e-mail 'Produtivo' (que requer a√ß√£o).

    Args:
        text (str): O corpo do e-mail.

    Returns:
        str or None: O n√∫mero de pedido encontrado ou None se nenhum for detectado.
    """
    text_low = text.lower()
    
    # Padr√£o 1: Busca por 'pedido' seguido opcionalmente por ':', espa√ßo ou '-' e, em seguida, pelo menos 4 d√≠gitos.
    # Ex: "pedido 1234", "pedido:5678", "pedido-9101"
    m = re.search(r'pedido[:\s-]*([0-9]{4,})', text_low)
    if m:
        return m.group(1) # Retorna o grupo de captura (apenas os d√≠gitos do pedido).
        
    # Padr√£o 2: Busca por uma sequ√™ncia isolada de 6 ou mais d√≠gitos.
    # O `\b` significa "word boundary" (fronteira de palavra), garantindo que n√£o pegamos
    # parte de um n√∫mero maior, como um CEP ou telefone.
    # Ex: "ID 123456", "rastreio 987654321"
    m2 = re.search(r'\b([0-9]{6,})\b', text_low)
    if m2:
        return m2.group(1)
        
    return None # Retorna None se nenhum padr√£o for encontrado.


# <<< IN√çCIO DA MELHORIA DO GPT >>>
# ### INCREMENTO: ASSINATURA DIN√ÇMICA ###
# A assinatura da fun√ß√£o foi modificada para aceitar 'user_name'
def template_reply(label, text="", user_name=""):
    """
    Gera uma resposta autom√°tica padronizada com base no r√≥tulo de classifica√ß√£o
    e ajustada por heur√≠stica para e-mails 'Produtivos'.

    üîß Melhorias: respostas contextuais para anexos, comunica√ß√£o formal e termos acad√™micos.
    """
    text_lower = text.lower()
    order_id = detect_order_info(text)
    
    # Vari√°vel para construir o corpo da resposta antes de adicionar a assinatura.
    reply_body = ""

    # L√≥gica para e-mails que requerem a√ß√£o (Produtivo)
    if label == "Produtivo":
        if order_id:
            reply_body = (f"Prezado(a),\n\nObrigado pelo contato. "
                          f"Identificamos o pedido #{order_id} em sua mensagem. "
                          "Estamos verificando e retornaremos com a nota fiscal ou atualiza√ß√£o do status em breve.")
        elif any(k in text_lower for k in ["nota fiscal", "nota-fiscal", "nf-e", "nota_fiscal"]):
            reply_body = ("Prezado(a),\n\nObrigado pelo contato. "
                          "Vamos verificar a nota fiscal solicitada e retornaremos assim que poss√≠vel.")
        elif any(k in text_lower for k in ["cancelamento", "devolu√ß√£o", "reembolso", "assinatura"]):
            reply_body = ("Prezado(a),\n\nRecebemos sua solicita√ß√£o. "
                          "Nossa equipe est√° analisando e retornar√° em breve.")
        elif any(k in text_lower for k in ["anexo", "slides", "curr√≠culo", "documento"]):
            reply_body = ("Prezado(a),\n\nObrigado pelo envio do material. "
                          "Ele ser√° muito √∫til e j√° estamos organizando para utiliza√ß√£o.")
        elif any(k in text_lower for k in ["professor", "aluno", "disciplina", "tarefa", "projeto", "atividade"]):
            reply_body = ("Prezado(a) Professor(a),\n\nAgradecemos a mensagem e o envio. "
                          "Estamos acompanhando com aten√ß√£o.")
        elif any(k in text_lower for k in ["prezado", "atenciosamente"]):
            reply_body = ("Prezado(a),\n\nAgradecemos o contato e confirmamos o recebimento da sua mensagem. "
                          "Nossa equipe est√° √† disposi√ß√£o.")
        else:
            reply_body = ("Prezado(a),\n\nRecebemos sua solicita√ß√£o e vamos analisar. "
                          "Por favor, confirme o n√∫mero do seu pedido ou envie mais detalhes, se aplic√°vel.")
    
    # L√≥gica para e-mails que n√£o requerem a√ß√£o imediata (Improdutivo)
    else:
        reply_body = ("Prezado(a),\n\nAgradecemos a sua mensagem. Entraremos em contato se for necess√°ria alguma a√ß√£o.")

    # ### INCREMENTO: ASSINATURA DIN√ÇMICA ###
    # L√≥gica para criar a assinatura. Se o nome for fornecido no formul√°rio, usa-o.
    # Caso contr√°rio, usa um placeholder gen√©rico que incentiva o preenchimento.
    signature = f"Atenciosamente,\n{user_name}" if user_name else "Atenciosamente,\n[Seu Nome]"
    
    # Concatena o corpo da resposta com a assinatura para formar a resposta final.
    return f"{reply_body}\n\n{signature}"
# <<< FIM DA MELHORIA DO GPT >>>


# --- Fun√ß√µes de Classifica√ß√£o com Modelos de IA ---

def classify_with_gemini(text, api_key):
    """
    Classifica o e-mail e gera resposta usando a API do Gemini.
    """
    if genai is None:
        return "Erro", 0.0, "A biblioteca do Google Gemini n√£o est√° instalada. Rode: pip install google-generativeai"

    try:
        genai.configure(api_key=api_key)
        model_gemini = genai.GenerativeModel(
            model_name="gemini-2.5-flash",
            generation_config={"temperature": 0}
        )
        prompt = (
            "Voc√™ √© um assistente de e-mail. Classifique o e-mail a seguir em 'Produtivo' ou 'Improdutivo' "
            "e gere o CORPO de uma resposta autom√°tica apropriada. Retorne SOMENTE um JSON v√°lido com os campos: "
            "'label' (string), 'confidence' (float entre 0.0 e 1.0), e 'reply' (string, sem assinatura). "
            f"E-mail para an√°lise: '''{text}'''"
        )
        response = model_gemini.generate_content(prompt)
        if hasattr(response, "text") and response.text:
            content = response.text
        elif hasattr(response, "candidates") and response.candidates:
            content = response.candidates[0].content.parts[0].text
        else:
            raise ValueError("N√£o foi poss√≠vel extrair o texto da resposta do Gemini.")
        content = content.strip().lstrip("```json").rstrip("```")
        parsed = json.loads(content)
        return parsed.get("label"), float(parsed.get("confidence", 0)), parsed.get("reply", "")

    except Exception as e:
        print(f"Erro na API do Gemini: {e}")
        return "Erro", 0.0, f"Ocorreu um erro ao comunicar com a API do Gemini: {e}"

def classify_with_openai(text, api_key):
    """
    Classifica o e-mail e gera resposta usando a API da OpenAI (GPT).
    """
    if openai is None:
        return "Erro", 0.0, "A biblioteca da OpenAI n√£o est√° instalada. Rode: pip install openai"

    try:
        openai.api_key = api_key
        prompt = (
            "Voc√™ √© um assistente de e-mail. Classifique o e-mail a seguir em 'Produtivo' ou 'Improdutivo' "
            "e gere o CORPO de uma resposta autom√°tica apropriada. Retorne SOMENTE um JSON v√°lido com os campos: "
            "'label' (string), 'confidence' (float entre 0.0 e 1.0), e 'reply' (string, sem assinatura). "
            f"E-mail para an√°lise: '''{text}'''"
        )
        resp = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        content = resp['choices'][0]['message']['content']
        parsed = json.loads(content)
        return parsed.get("label"), float(parsed.get("confidence", 0)), parsed.get("reply", "")

    except Exception as e:
        print(f"Erro na API da OpenAI: {e}")
        return "Erro", 0.0, f"Ocorreu um erro ao comunicar com a API da OpenAI: {e}"


def classify_local(text, user_name=""):
    """
    Usa o modelo de Machine Learning local para classifica√ß√£o.
    """
    if model is None:
        return "Erro", 0.0, "O modelo local n√£o est√° carregado. Treine o modelo primeiro."
    try:
        proba_prod = float(model.predict_proba([text])[0][1])
        if detect_order_info(text):
            proba_prod = max(proba_prod, 0.85)
        if any(k in text.lower() for k in ["anexo", "slides", "professor", "disciplina", "curr√≠culo", "documento"]):
            proba_prod = max(proba_prod, 0.8)

        if proba_prod >= 0.6:
            label = "Produtivo"
            confidence = proba_prod
        else:
            label = "Improdutivo"
            confidence = 1 - proba_prod
            if proba_prod >= 0.5:
                print("Aviso: classifica√ß√£o incerta (zona 0.5‚Äì0.6), revis√£o humana sugerida.")
        
        reply = template_reply(label, text, user_name)
        return label, confidence, reply
        
    except Exception as e:
        print(f"Erro no modelo local: {e}")
        return "Erro", 0.0, "Ocorreu um erro ao usar o modelo local."


# --- Rotas da Aplica√ß√£o Flask ---

# ### INCREMENTO: VERIFICA√á√ÉO DE CHAVES DE AMBIENTE ###
# A rota principal agora verifica se as chaves de API existem no ambiente do servidor
# e passa essa informa√ß√£o para o template.
@app.route("/", methods=["GET"])
def index():
    """
    Rota principal (GET). 
    Renderiza o template 'index.html', passando o status das chaves de API do ambiente.
    """
    # os.getenv() busca uma vari√°vel de ambiente. Retorna None se n√£o encontrar.
    # A convers√£o para bool (!!os.getenv(...)) resulta em True se a chave existir e False se n√£o.
    gemini_key_exists = bool(os.getenv("GEMINI_API_KEY"))
    openai_key_exists = bool(os.getenv("OPENAI_API_KEY"))
    
    print(f"Status da chave Gemini no ambiente: {gemini_key_exists}")
    print(f"Status da chave OpenAI no ambiente: {openai_key_exists}")
    
    # Passa as vari√°veis booleanas para o template.
    return render_template("index.html", 
                           gemini_key_exists=gemini_key_exists, 
                           openai_key_exists=openai_key_exists)


@app.route("/process", methods=["POST"])
def process():
    """
    Rota de processamento (POST). 
    Recebe os dados do formul√°rio, executa a classifica√ß√£o e renderiza os resultados.
    """
    try:
        # 1. Coleta e Sanitiza os Dados do Formul√°rio
        text_input = request.form.get("text_input", "").strip()
        mode = request.form.get("mode", "local")
        api_key = request.form.get("api_key", "").strip()
        file = request.files.get("file")
        user_name = request.form.get("user_name", "").strip()
        
        # ### INCREMENTO: VERIFICA√á√ÉO DE CHAVES DE AMBIENTE (RE-RENDERIZA√á√ÉO) ###
        # √â importante verificar o status das chaves aqui tamb√©m, para que a informa√ß√£o
        # seja passada de volta ao template em caso de erro ou sucesso.
        gemini_key_exists = bool(os.getenv("GEMINI_API_KEY"))
        openai_key_exists = bool(os.getenv("OPENAI_API_KEY"))
        # Monta um dicion√°rio com os dados a serem passados de volta para o template.
        # Isso evita repeti√ß√£o de c√≥digo nos retornos.
        render_data = {
            "selected_mode": mode,
            "user_name": user_name,
            "gemini_key_exists": gemini_key_exists,
            "openai_key_exists": openai_key_exists
        }

        text = None
        
        # Corre√ß√£o Bug 2: Prioridade do Arquivo
        if file and file.filename:
            filename = file.filename.lower()
            if filename.endswith(".pdf"):
                text = extract_text_from_pdf(io.BytesIO(file.read()))
            elif filename.endswith(".txt"):
                text = file.read().decode("utf-8", errors="ignore")
        
        if not text:
            text = text_input

        # 3. Valida√ß√£o do Texto Final
        if not text:
            render_data["error"] = "Nenhum texto ou arquivo v√°lido foi enviado."
            return render_template("index.html", **render_data)

        # 4. Execu√ß√£o da Classifica√ß√£o Baseada no Modo
        label, confidence, reply = "", 0.0, ""

        if mode == "local":
            label, confidence, reply = classify_local(text, user_name)
        
        elif mode == "gemini" or mode == "openai":
            reply_body = ""
            key_to_use = api_key # Por padr√£o, usa a chave do formul√°rio.
            
            if mode == "gemini":
                # Se a chave de ambiente do Gemini existir, ela tem prioridade.
                if gemini_key_exists:
                    key_to_use = os.getenv("GEMINI_API_KEY")
                # Se n√£o existir nem no ambiente nem no formul√°rio, retorna erro.
                if not key_to_use:
                    render_data["error"] = "Chave de API do Gemini n√£o fornecida."
                    return render_template("index.html", **render_data)
                label, confidence, reply_body = classify_with_gemini(text, key_to_use)

            else: # openai
                # Se a chave de ambiente do OpenAI existir, ela tem prioridade.
                if openai_key_exists:
                    key_to_use = os.getenv("OPENAI_API_KEY")
                # Se n√£o existir nem no ambiente nem no formul√°rio, retorna erro.
                if not key_to_use:
                    render_data["error"] = "Chave de API da OpenAI n√£o fornecida."
                    return render_template("index.html", **render_data)
                label, confidence, reply_body = classify_with_openai(text, key_to_use)
            
            # Adiciona a assinatura din√¢mica √† resposta vinda da API
            if label != "Erro":
                signature = f"\n\nAtenciosamente,\n{user_name}" if user_name else "\n\nAtenciosamente,\n[Seu Nome]"
                reply = reply_body + signature
            else:
                reply = reply_body # Em caso de erro, a resposta j√° √© a mensagem de erro.
        else:
            render_data["error"] = "Modo de opera√ß√£o inv√°lido."
            return render_template("index.html", **render_data)

        # 5. Tratamento de Erros de Classifica√ß√£o
        if label == "Erro":
            render_data["error"] = reply
            render_data["original_text"] = text
            return render_template("index.html", **render_data)

        # 6. Renderiza√ß√£o de Resultados
        # Adiciona os resultados ao dicion√°rio de dados e renderiza o template.
        render_data.update({
            "original_text": text,
            "result_label": label,
            "confidence": confidence,
            "suggested_reply": reply,
        })
        return render_template("index.html", **render_data)

    except Exception as e:
        print(f"Erro geral na rota /process: {e}")
        traceback.print_exc()
        return render_template("index.html", error="Ocorreu um erro inesperado no servidor.")


# --- Execu√ß√£o da Aplica√ß√£o ---
if __name__ == "__main__":
    app.run(debug=True, port=5000)